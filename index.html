<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="description" content="RL results">
    <meta name="author" content="K. Danieli">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <title>RL Cognitive Maps</title>
    <!-- Link to the external CSS file -->
    <link rel="stylesheet" href="style.css"> 
</head>
<body>
    <!-- TITLE -->
    <h1 class="header_title">
        Neuromodulated online cognitive maps for reinforcement learning
    </h1>
    <h2 class="header_authors">
        <i>K. Danieli<sup>1</sup>, M.E.Lepper√∏d<sup>2</sup>, M.Fyhn<sup>1,2</sup></i>
    </h2>
    <h3 class="header_affiliations">
            <i><sup>1</sup>Department of Biosciences, University of Oslo<br>
                <sup>2</sup>Simula Research Laboratory</i>
    </h3>
    <hr>

    <!-- LOGOS -->
    <div class="header_logos">
        <div class="header_logo_bioai">
            <img src="media/bioAI_logo.png" alt="BioAI logo" width="80" height="60">
        </div>  
        <div class="header_logo_uio">
            <img src="media/logo_UiO short.png" alt="UiO logo" width="105" height="60">
        </div>
    </div>

    <!-- Architecture model -->
    <div class="model-container">
        <div class="model-box">
                <div class="text_caption_1">
                <h3>Architecture: Place Cell Neural Network</h3>
                The model is structured is two component: a spatial layer, whose purpose is to receive a 2D position and cast it to an higher dimensional space (here by means of Gaussian place fields), and a network of un-tuned neurons, which receives the activation of the upstream layer. During
                    training, through competitive dynamics and homeostatic mechanisms, the un-tuned neurons progressively form spatial fields over the input representation, becoming place cells (and hence the name <i>PCNN</i>. Plasticity is supported by <span style="color:
                        blue">cholinergic</span> (ACh)
                    and <span style="color: green">dopaminergic</span> (DA) stimulation, which work as finite synaptic resources.
                </div>
            <figure>
                <img id="arc-mod" src="media/new_minimal_architecture.png" alt="Architecture 1">
            </figure>
        </div>
    </div>

    <!-- GIFs buttons -->
    <!-- GIFs -->
    <div class="gif-container">
        <div class="gif-box">
            <div class="text_caption_1">
                <h3>Formation of a cognitive map</h3>
                    An agent endowed with the PCNN model roams a 2D environment with a random <span style="color: red">trajectory</span>. As it goes, it builds a spatial representation by tuning cells to its current position. These <span style="color: blue">place cells</span> (PCs) form a network (graph)
                    with <span style="color: blue">connections</span> defined through a K-Neareast Neighbor algorithm (within a certain distance). The <i>formation</i> of new cells is modulated by the level of <span style="color: blue">acetilcholine</span> (ACh). When the agent passes near a rewarded
                    area, it receives a spike of <span style="color: green">dopamine</span> (DA), which modulates the <i>spatial remapping</i> of nearby place cells towards its current position.
            </div>
            <div class="button-container">
                <button id="restart-button1">restart gif</button>
            </div>
            <figure>
                <img id="pcnn-gif1" src="media/roaming_2_static.png" alt="PCNN GIF 1">
            </figure>
        </div>

    <!-- Policy -->
    <div class="model-container">
        <div class="model-box">
                <div class="text_caption_1">
                <h3>Exploitation of the cognitive map</h3>
                    Once the agent has formed a spatial representation, it can use it to navigate towards a target location.
                        The algorithm implemented here is based on matching the population vector (<i>i.e.</i> representation) corresponding to the current location
                        with the desired one by taking the <i>cosine similarity</i> and map it onto the 2D space. The desired representation is calculated as the weighted sum (parametrized by \(\epsilon\)) of the representation of the proximal and the target location. In particular, the proximal
                        positions (in terms of spatial representation) are obtained by making an internal step in the network using the recurrent weights. Further, the function \(\varphi\) can modulate the activation of the active neurons and prioritize the highest or lowest active ones
                        \(\varphi(\vec{u})=\vec{u}+\lambda(\langle\vec{u}\rangle-\vec{u})\), this can be useful when the agent get stuck (<i>e.g.</i> not following the straightest route might be better).
                </div>
            <figure>
                <img id="policy-desc" src="media/policy_1.png" alt="Policy 1">
            </figure>
        </div>
    </div>

    <!-- Target-reaching behaviour -->
    <div class="gif-box wider">
        <div class="text_caption_1">
            <h3>Implementation</h3>
                    A simulation has been implemented using various environments, here for example it is chosen a square arena with a wall in between, to test the agent's ability to navigate towards a <span style="color: green">target</span> location. The agent is initialized in a random position and the target is placed in the opposite
                    corner. The agent is allowed to move in the 2D space, and the policy is implemented as illustrated above. It is also plotted a record of the current population vector (representation) and the target one. The flashing nodes in the arena correspond to the neurons active in the representation
                    of the next position and correspond to the locations where the agent "thinks" it can move, the actual action is a sort of weighted average of the place field centers of these active neurons.
        </div>
        <div class="button-container">
            <button id="restart-button2">restart gif</button>
        </div>
        <figure>
            <img id="pcnn-gif2" src="media/rlroom_e_1_static.png" alt="PCNN GIF 2">
        </figure>
    </div>
    </div>

    <!-- SCRIPT -->
    <script>
        const gif1 = document.getElementById('pcnn-gif1');
        const button1 = document.getElementById('restart-button1');
        const gif2 = document.getElementById('pcnn-gif2');
        const button2 = document.getElementById('restart-button2');
        button1.addEventListener('click', () => {
            gif1.src = 'media/roaming_2.gif';
        });
        button2.addEventListener('click', () => {
            gif2.src = 'media/rlroom_e_1.gif';
        });
    </script>
</body>
</html>
